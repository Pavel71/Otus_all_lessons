{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tqdm\n",
    "import warnings\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "# Для кириллицы на графиках\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import scipy.stats as scs\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача:\n",
    "    Расчитать продажы для магазинов в будущем\n",
    "    Использую те фичи которые представленные в teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data_train = pd.read_csv('train.csv.zip')\n",
    "data_test = pd.read_csv('test.csv.zip')\n",
    "data_store = pd.read_csv('store.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_store.merge(data_train,on='Store')\n",
    "df_test = data_test.merge(data_store, on = 'Store')\n",
    "\n",
    "# На обучение учитываем только открытые магазины\n",
    "df = df[df['Open'] != 0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Собираю Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import  LabelEncoder, LabelBinarizer, OneHotEncoder\n",
    "from sklearn.pipeline import make_union, make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, Imputer\n",
    "from sklearn.preprocessing import CategoricalEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class Simple_pipeline(BaseEstimator):\n",
    "    \n",
    "    \"\"\"\n",
    "    Класс обработки данных и применения к ним линейной регрессии\n",
    "    \n",
    "    Объект использует метод get_pipline\n",
    "    Принимает DataFrame\n",
    "    Возвращает обработанную разряженную матрицу \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "        \n",
    "\n",
    "    def get_date(self,df):\n",
    "        \n",
    "        \"\"\"\n",
    "        Функция создает новые фьючерсы по отдельности дни недели и месяцы\n",
    "        Использует фьючерс Day\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        df['Year'] = df['Date'].apply(lambda x: int(x[:4]))\n",
    "        df['Month'] = df['Date'].apply(lambda x: int(x[5:7]))\n",
    "        df['Day'] = df['Date'].apply(lambda x: int(x[8:]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        return df[['Month','Day','Year']]\n",
    "    \n",
    "    def fill_nan_future_float(self,df):\n",
    "        \n",
    "        \"\"\"\n",
    "        Функция принимает DataFrame \n",
    "        \n",
    "        Берет признаки с типом float\n",
    "        \n",
    "        Заполняет все пропуски 0\n",
    "        \n",
    "        Возвращает эти признаки в пайплайн \n",
    "        \n",
    "        - Важно указать Стандартизацию данных\n",
    "        \n",
    "        \"\"\"\n",
    "        # В тесте есть баг его надо поправить\n",
    "        df['Open'].fillna(1,inplace=True)\n",
    "        df['Open'] = df['Open'].astype('int64')\n",
    "            \n",
    "        name_float = []\n",
    "        for name in df.columns:\n",
    "    \n",
    "            if df[name].dtype == 'float64':\n",
    "            \n",
    "                name_float.append(name)\n",
    "                df[name].fillna(df[name].mean(),inplace=True)\n",
    "        \n",
    "        return df[name_float]\n",
    "    \n",
    "    def work_object_future(self,df):\n",
    "        \n",
    "        \"\"\"\n",
    "        Функция принимает DataFrame\n",
    "        Работаем здесь с Фичами объекты заполнение и подготовка к onehot encoding\n",
    "        Возвращаю Фьючи для Categorical Encoding\n",
    "        \n",
    "        - Для линейной регресси делаем onehotencoding\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Сначала обработаем фичу 'PromoInterval'] Она содержит и пропуски и строковые обозначения с запятыми\n",
    "        # преобразуем этот признак\n",
    "        \n",
    "        # уберем запятые чтобы Mar,Jun,Sept,Dec принял вид MarJunSeptDec и заполним пропуски \"0\"\n",
    "        df['PromoInterval'] = df['PromoInterval'].apply(lambda x: x.replace(',','') if x == x else '0')\n",
    "        \n",
    "        # Подправим небольшой баг в признаке  StateHoliday\n",
    "        df['StateHoliday'] = df['StateHoliday'].replace(0, '0')\n",
    "        \n",
    "        return df[['Store','StoreType', 'Assortment','Promo2', 'PromoInterval','DayOfWeek','Open','Promo','StateHoliday','SchoolHoliday']]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_pipline(self):\n",
    "\n",
    "        pipeline = make_union(*[\n",
    "            \n",
    "            # 1 Создаем Новые признаки День и месяц\n",
    "            make_pipeline(FunctionTransformer(self.get_date, validate=False)),\n",
    "                          \n",
    "            # 2 Заполняем все числовые признаки 0\n",
    "            make_pipeline(FunctionTransformer(self.fill_nan_future_float, validate=False),StandardScaler()),\n",
    "            \n",
    "            # 3 Преобразуем категориальные признаки\n",
    "            make_pipeline(FunctionTransformer(self.work_object_future, validate=False),CategoricalEncoder(encoding='ordinal'))\n",
    "            \n",
    "            \n",
    "        ])\n",
    "        \n",
    "        return pipeline.fit_transform(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipline = Simple_pipeline(df).get_pipline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipline = Simple_pipeline(df_test).get_pipline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((844392, 18), (41088, 18))"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_pipline.shape, test_pipline.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(844392,)"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Sales']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Учтем временной период! Обучим на начале выборки протестируем в конце\n",
    "train_size = int(train_pipline.shape[0]*.98)\n",
    "X_train, y_train = train_pipline[:train_size], y[:train_size]\n",
    "X_test, y_test = train_pipline[train_size:], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Следубщий код вщять с кэгла! Метрика \n",
    "\n",
    "def ToWeight(y):\n",
    "    w = np.zeros(y.shape, dtype=float)\n",
    "    ind = y != 0\n",
    "    w[ind] = 1./(y[ind]**2)\n",
    "    return w\n",
    "\n",
    "\n",
    "def rmspe(yhat, y):\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n",
    "    return rmspe\n",
    "\n",
    "\n",
    "def rmspe_xg(yhat, y):\n",
    "    # y = y.values\n",
    "    y = y.get_label()\n",
    "    y = np.exp(y) - 1\n",
    "    yhat = np.exp(yhat) - 1\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean(w * (y - yhat)**2))\n",
    "    return \"rmspe\", rmspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучим XGBoost\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "params = {\"objective\": \"reg:linear\",\n",
    "          \"eta\": 0.3,\n",
    "          \"max_depth\": 8,\n",
    "          \"subsample\": 0.7,\n",
    "          \"colsample_bytree\": 0.7,\n",
    "          \"silent\": 1\n",
    "          }\n",
    "num_trees = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:5.76525\ttrain-rmse:5.79447\teval-rmspe:0.996648\ttrain-rmspe:0.9968\n",
      "Multiple eval metrics have been passed: 'train-rmspe' will be used for early stopping.\n",
      "\n",
      "Will train until train-rmspe hasn't improved in 50 rounds.\n",
      "[1]\teval-rmse:4.03497\ttrain-rmse:4.06451\teval-rmspe:0.980543\ttrain-rmspe:0.981398\n",
      "[2]\teval-rmse:2.8316\ttrain-rmse:2.8555\teval-rmspe:0.935398\ttrain-rmspe:0.937844\n",
      "[3]\teval-rmse:1.98833\ttrain-rmse:2.01298\teval-rmspe:0.851412\ttrain-rmspe:0.856237\n",
      "[4]\teval-rmse:1.40901\ttrain-rmse:1.42875\teval-rmspe:0.740795\ttrain-rmspe:0.743241\n",
      "[5]\teval-rmse:1.00732\ttrain-rmse:1.02738\teval-rmspe:0.629199\ttrain-rmspe:0.619027\n",
      "[6]\teval-rmse:0.748134\ttrain-rmse:0.752721\teval-rmspe:0.55119\ttrain-rmspe:0.505526\n",
      "[7]\teval-rmse:0.581209\ttrain-rmse:0.569934\teval-rmspe:0.513984\ttrain-rmspe:0.417714\n",
      "[8]\teval-rmse:0.485106\ttrain-rmse:0.450467\teval-rmspe:0.527615\ttrain-rmspe:0.356284\n",
      "[9]\teval-rmse:0.436194\ttrain-rmse:0.377074\teval-rmspe:0.554924\ttrain-rmspe:0.323405\n",
      "[10]\teval-rmse:0.405674\ttrain-rmse:0.335621\teval-rmspe:0.583412\ttrain-rmspe:0.311298\n",
      "[11]\teval-rmse:0.392926\ttrain-rmse:0.31073\teval-rmspe:0.619236\ttrain-rmspe:0.308579\n",
      "[12]\teval-rmse:0.392421\ttrain-rmse:0.295312\teval-rmspe:0.648041\ttrain-rmspe:0.309387\n",
      "[13]\teval-rmse:0.399029\ttrain-rmse:0.287098\teval-rmspe:0.692049\ttrain-rmspe:0.312529\n",
      "[14]\teval-rmse:0.399691\ttrain-rmse:0.282248\teval-rmspe:0.713035\ttrain-rmspe:0.31471\n",
      "[15]\teval-rmse:0.402021\ttrain-rmse:0.274362\teval-rmspe:0.737955\ttrain-rmspe:0.311498\n",
      "[16]\teval-rmse:0.403544\ttrain-rmse:0.269915\teval-rmspe:0.745116\ttrain-rmspe:0.310431\n",
      "[17]\teval-rmse:0.397284\ttrain-rmse:0.26173\teval-rmspe:0.744753\ttrain-rmspe:0.303732\n",
      "[18]\teval-rmse:0.39647\ttrain-rmse:0.254639\teval-rmspe:0.74809\ttrain-rmspe:0.296525\n",
      "[19]\teval-rmse:0.398282\ttrain-rmse:0.248805\teval-rmspe:0.752959\ttrain-rmspe:0.290585\n",
      "[20]\teval-rmse:0.398015\ttrain-rmse:0.246577\teval-rmspe:0.742948\ttrain-rmspe:0.28615\n",
      "[21]\teval-rmse:0.396974\ttrain-rmse:0.244485\teval-rmspe:0.740374\ttrain-rmspe:0.284227\n",
      "[22]\teval-rmse:0.396187\ttrain-rmse:0.236443\teval-rmspe:0.753973\ttrain-rmspe:0.27688\n",
      "[23]\teval-rmse:0.400153\ttrain-rmse:0.230241\teval-rmspe:0.761782\ttrain-rmspe:0.270684\n",
      "[24]\teval-rmse:0.400444\ttrain-rmse:0.222425\teval-rmspe:0.763043\ttrain-rmspe:0.261999\n",
      "[25]\teval-rmse:0.402874\ttrain-rmse:0.2172\teval-rmspe:0.768385\ttrain-rmspe:0.256555\n",
      "[26]\teval-rmse:0.402844\ttrain-rmse:0.2168\teval-rmspe:0.769848\ttrain-rmspe:0.256348\n",
      "[27]\teval-rmse:0.405665\ttrain-rmse:0.213926\teval-rmspe:0.783296\ttrain-rmspe:0.253434\n",
      "[28]\teval-rmse:0.406552\ttrain-rmse:0.210755\teval-rmspe:0.792066\ttrain-rmspe:0.249724\n",
      "[29]\teval-rmse:0.406717\ttrain-rmse:0.203698\teval-rmspe:0.786942\ttrain-rmspe:0.242508\n",
      "[30]\teval-rmse:0.407857\ttrain-rmse:0.201637\teval-rmspe:0.78664\ttrain-rmspe:0.240442\n",
      "[31]\teval-rmse:0.410472\ttrain-rmse:0.198179\teval-rmspe:0.790368\ttrain-rmspe:0.234596\n",
      "[32]\teval-rmse:0.411239\ttrain-rmse:0.196888\teval-rmspe:0.783597\ttrain-rmspe:0.232706\n",
      "[33]\teval-rmse:0.411235\ttrain-rmse:0.19402\teval-rmspe:0.783583\ttrain-rmspe:0.229815\n",
      "[34]\teval-rmse:0.410995\ttrain-rmse:0.192868\teval-rmspe:0.774987\ttrain-rmspe:0.228548\n",
      "[35]\teval-rmse:0.413154\ttrain-rmse:0.191639\teval-rmspe:0.763945\ttrain-rmspe:0.227425\n",
      "[36]\teval-rmse:0.413217\ttrain-rmse:0.190035\teval-rmspe:0.764177\ttrain-rmspe:0.22574\n",
      "[37]\teval-rmse:0.414551\ttrain-rmse:0.187839\teval-rmspe:0.765069\ttrain-rmspe:0.223168\n",
      "[38]\teval-rmse:0.414317\ttrain-rmse:0.187056\teval-rmspe:0.763885\ttrain-rmspe:0.221676\n",
      "[39]\teval-rmse:0.414738\ttrain-rmse:0.186166\teval-rmspe:0.755713\ttrain-rmspe:0.220764\n",
      "[40]\teval-rmse:0.414007\ttrain-rmse:0.18231\teval-rmspe:0.759932\ttrain-rmspe:0.215916\n",
      "[41]\teval-rmse:0.418768\ttrain-rmse:0.18047\teval-rmspe:0.772717\ttrain-rmspe:0.214169\n",
      "[42]\teval-rmse:0.418569\ttrain-rmse:0.180032\teval-rmspe:0.771894\ttrain-rmspe:0.213743\n",
      "[43]\teval-rmse:0.421527\ttrain-rmse:0.176358\teval-rmspe:0.777005\ttrain-rmspe:0.210825\n",
      "[44]\teval-rmse:0.422049\ttrain-rmse:0.175619\teval-rmspe:0.777369\ttrain-rmspe:0.210111\n",
      "[45]\teval-rmse:0.423329\ttrain-rmse:0.174033\teval-rmspe:0.779638\ttrain-rmspe:0.208174\n",
      "[46]\teval-rmse:0.423341\ttrain-rmse:0.17302\teval-rmspe:0.779679\ttrain-rmspe:0.207105\n",
      "[47]\teval-rmse:0.423545\ttrain-rmse:0.171983\teval-rmspe:0.778801\ttrain-rmspe:0.204916\n",
      "[48]\teval-rmse:0.423623\ttrain-rmse:0.171665\teval-rmspe:0.77868\ttrain-rmspe:0.204583\n",
      "[49]\teval-rmse:0.423765\ttrain-rmse:0.169902\teval-rmspe:0.7786\ttrain-rmspe:0.202967\n",
      "[50]\teval-rmse:0.421451\ttrain-rmse:0.168867\teval-rmspe:0.777764\ttrain-rmspe:0.202061\n",
      "[51]\teval-rmse:0.420703\ttrain-rmse:0.16815\teval-rmspe:0.772867\ttrain-rmspe:0.201338\n",
      "[52]\teval-rmse:0.420688\ttrain-rmse:0.167546\teval-rmspe:0.772812\ttrain-rmspe:0.20077\n",
      "[53]\teval-rmse:0.419939\ttrain-rmse:0.165985\teval-rmspe:0.771246\ttrain-rmspe:0.199291\n",
      "[54]\teval-rmse:0.418795\ttrain-rmse:0.16444\teval-rmspe:0.765891\ttrain-rmspe:0.198177\n",
      "[55]\teval-rmse:0.418851\ttrain-rmse:0.163303\teval-rmspe:0.766091\ttrain-rmspe:0.197153\n",
      "[56]\teval-rmse:0.41817\ttrain-rmse:0.161994\teval-rmspe:0.764599\ttrain-rmspe:0.19587\n",
      "[57]\teval-rmse:0.418588\ttrain-rmse:0.159949\teval-rmspe:0.765626\ttrain-rmspe:0.193688\n",
      "[58]\teval-rmse:0.41859\ttrain-rmse:0.15946\teval-rmspe:0.765633\ttrain-rmspe:0.193247\n",
      "[59]\teval-rmse:0.418593\ttrain-rmse:0.158977\teval-rmspe:0.765642\ttrain-rmspe:0.193502\n",
      "[60]\teval-rmse:0.417755\ttrain-rmse:0.158797\teval-rmspe:0.765809\ttrain-rmspe:0.193334\n",
      "[61]\teval-rmse:0.417978\ttrain-rmse:0.158174\teval-rmspe:0.766197\ttrain-rmspe:0.192785\n",
      "[62]\teval-rmse:0.417321\ttrain-rmse:0.157057\teval-rmspe:0.764752\ttrain-rmspe:0.191549\n",
      "[63]\teval-rmse:0.417326\ttrain-rmse:0.156338\teval-rmspe:0.76477\ttrain-rmspe:0.190737\n",
      "[64]\teval-rmse:0.417343\ttrain-rmse:0.155058\teval-rmspe:0.764829\ttrain-rmspe:0.18896\n",
      "[65]\teval-rmse:0.418431\ttrain-rmse:0.153518\teval-rmspe:0.763358\ttrain-rmspe:0.187592\n",
      "[66]\teval-rmse:0.418301\ttrain-rmse:0.152782\teval-rmspe:0.762071\ttrain-rmspe:0.186511\n",
      "[67]\teval-rmse:0.418019\ttrain-rmse:0.151729\teval-rmspe:0.76036\ttrain-rmspe:0.185508\n",
      "[68]\teval-rmse:0.418007\ttrain-rmse:0.150799\teval-rmspe:0.75766\ttrain-rmspe:0.184889\n",
      "[69]\teval-rmse:0.41786\ttrain-rmse:0.150205\teval-rmspe:0.754208\ttrain-rmspe:0.184303\n",
      "[70]\teval-rmse:0.417861\ttrain-rmse:0.149929\teval-rmspe:0.754111\ttrain-rmspe:0.184058\n",
      "[71]\teval-rmse:0.416912\ttrain-rmse:0.149332\teval-rmspe:0.752584\ttrain-rmspe:0.183151\n",
      "[72]\teval-rmse:0.417498\ttrain-rmse:0.148672\teval-rmspe:0.751439\ttrain-rmspe:0.182487\n",
      "[73]\teval-rmse:0.417488\ttrain-rmse:0.148354\teval-rmspe:0.75156\ttrain-rmspe:0.181811\n",
      "[74]\teval-rmse:0.416762\ttrain-rmse:0.147998\teval-rmspe:0.747287\ttrain-rmspe:0.181505\n",
      "[75]\teval-rmse:0.416459\ttrain-rmse:0.147196\teval-rmspe:0.746466\ttrain-rmspe:0.180792\n",
      "[76]\teval-rmse:0.417292\ttrain-rmse:0.146683\teval-rmspe:0.747029\ttrain-rmspe:0.180415\n",
      "[77]\teval-rmse:0.417282\ttrain-rmse:0.146448\teval-rmspe:0.74699\ttrain-rmspe:0.180117\n",
      "[78]\teval-rmse:0.417502\ttrain-rmse:0.145863\teval-rmspe:0.747398\ttrain-rmspe:0.179656\n",
      "[79]\teval-rmse:0.417362\ttrain-rmse:0.145518\teval-rmspe:0.74406\ttrain-rmspe:0.179407\n",
      "[80]\teval-rmse:0.417195\ttrain-rmse:0.14472\teval-rmspe:0.741722\ttrain-rmspe:0.178767\n",
      "[81]\teval-rmse:0.417031\ttrain-rmse:0.143792\teval-rmspe:0.742594\ttrain-rmspe:0.177686\n",
      "[82]\teval-rmse:0.417184\ttrain-rmse:0.143562\teval-rmspe:0.742811\ttrain-rmspe:0.177414\n",
      "[83]\teval-rmse:0.417195\ttrain-rmse:0.143301\teval-rmspe:0.742934\ttrain-rmspe:0.177122\n",
      "[84]\teval-rmse:0.417175\ttrain-rmse:0.142934\teval-rmspe:0.742859\ttrain-rmspe:0.176817\n",
      "[85]\teval-rmse:0.418129\ttrain-rmse:0.142734\teval-rmspe:0.748092\ttrain-rmspe:0.176582\n",
      "[86]\teval-rmse:0.418065\ttrain-rmse:0.142402\teval-rmspe:0.746062\ttrain-rmspe:0.176327\n",
      "[87]\teval-rmse:0.417764\ttrain-rmse:0.142168\teval-rmspe:0.745703\ttrain-rmspe:0.176125\n",
      "[88]\teval-rmse:0.41768\ttrain-rmse:0.142088\teval-rmspe:0.744659\ttrain-rmspe:0.176055\n",
      "[89]\teval-rmse:0.417679\ttrain-rmse:0.141607\teval-rmspe:0.743971\ttrain-rmspe:0.17564\n",
      "[90]\teval-rmse:0.417851\ttrain-rmse:0.141263\teval-rmspe:0.744245\ttrain-rmspe:0.175305\n",
      "[91]\teval-rmse:0.417889\ttrain-rmse:0.14104\teval-rmspe:0.743858\ttrain-rmspe:0.175088\n",
      "[92]\teval-rmse:0.418136\ttrain-rmse:0.140841\teval-rmspe:0.743844\ttrain-rmspe:0.174776\n",
      "[93]\teval-rmse:0.417995\ttrain-rmse:0.140466\teval-rmspe:0.743499\ttrain-rmspe:0.174459\n",
      "[94]\teval-rmse:0.418148\ttrain-rmse:0.139799\teval-rmspe:0.743613\ttrain-rmspe:0.173893\n",
      "[95]\teval-rmse:0.418121\ttrain-rmse:0.13944\teval-rmspe:0.743521\ttrain-rmspe:0.173541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96]\teval-rmse:0.418408\ttrain-rmse:0.139059\teval-rmspe:0.742592\ttrain-rmspe:0.173195\n",
      "[97]\teval-rmse:0.41857\ttrain-rmse:0.138655\teval-rmspe:0.744178\ttrain-rmspe:0.174669\n",
      "[98]\teval-rmse:0.418437\ttrain-rmse:0.138441\teval-rmspe:0.743982\ttrain-rmspe:0.174469\n",
      "[99]\teval-rmse:0.418368\ttrain-rmse:0.138004\teval-rmspe:0.743145\ttrain-rmspe:0.17415\n",
      "[100]\teval-rmse:0.418242\ttrain-rmse:0.137593\teval-rmspe:0.74305\ttrain-rmspe:0.173835\n",
      "[101]\teval-rmse:0.418219\ttrain-rmse:0.137234\teval-rmspe:0.743139\ttrain-rmspe:0.173481\n",
      "[102]\teval-rmse:0.418081\ttrain-rmse:0.136809\teval-rmspe:0.742678\ttrain-rmspe:0.172532\n",
      "[103]\teval-rmse:0.417977\ttrain-rmse:0.136571\teval-rmspe:0.742512\ttrain-rmspe:0.172423\n",
      "[104]\teval-rmse:0.418711\ttrain-rmse:0.13648\teval-rmspe:0.744884\ttrain-rmspe:0.172332\n",
      "[105]\teval-rmse:0.418801\ttrain-rmse:0.135905\teval-rmspe:0.745234\ttrain-rmspe:0.171894\n",
      "[106]\teval-rmse:0.418597\ttrain-rmse:0.135559\teval-rmspe:0.744529\ttrain-rmspe:0.171505\n",
      "[107]\teval-rmse:0.418603\ttrain-rmse:0.135254\teval-rmspe:0.744726\ttrain-rmspe:0.170966\n",
      "[108]\teval-rmse:0.418598\ttrain-rmse:0.13501\teval-rmspe:0.74471\ttrain-rmspe:0.170752\n",
      "[109]\teval-rmse:0.418591\ttrain-rmse:0.134747\teval-rmspe:0.744919\ttrain-rmspe:0.170208\n",
      "[110]\teval-rmse:0.41868\ttrain-rmse:0.134483\teval-rmspe:0.745367\ttrain-rmspe:0.169962\n",
      "[111]\teval-rmse:0.418661\ttrain-rmse:0.134205\teval-rmspe:0.745258\ttrain-rmspe:0.169696\n",
      "[112]\teval-rmse:0.418189\ttrain-rmse:0.133955\teval-rmspe:0.745465\ttrain-rmspe:0.169547\n",
      "[113]\teval-rmse:0.418142\ttrain-rmse:0.133773\teval-rmspe:0.74542\ttrain-rmspe:0.169511\n",
      "[114]\teval-rmse:0.418157\ttrain-rmse:0.133322\teval-rmspe:0.745095\ttrain-rmspe:0.169431\n",
      "[115]\teval-rmse:0.417665\ttrain-rmse:0.132995\teval-rmspe:0.743815\ttrain-rmspe:0.168908\n",
      "[116]\teval-rmse:0.417759\ttrain-rmse:0.132691\teval-rmspe:0.737836\ttrain-rmspe:0.168633\n",
      "[117]\teval-rmse:0.417775\ttrain-rmse:0.132531\teval-rmspe:0.73789\ttrain-rmspe:0.168451\n",
      "[118]\teval-rmse:0.41764\ttrain-rmse:0.132207\teval-rmspe:0.737227\ttrain-rmspe:0.168186\n",
      "[119]\teval-rmse:0.417635\ttrain-rmse:0.132093\teval-rmspe:0.737209\ttrain-rmspe:0.168091\n",
      "[120]\teval-rmse:0.417681\ttrain-rmse:0.131832\teval-rmspe:0.737058\ttrain-rmspe:0.167802\n",
      "[121]\teval-rmse:0.417822\ttrain-rmse:0.131647\teval-rmspe:0.737515\ttrain-rmspe:0.167502\n",
      "[122]\teval-rmse:0.418515\ttrain-rmse:0.131571\teval-rmspe:0.738728\ttrain-rmspe:0.16744\n",
      "[123]\teval-rmse:0.41832\ttrain-rmse:0.131318\teval-rmspe:0.737729\ttrain-rmspe:0.167154\n",
      "[124]\teval-rmse:0.418128\ttrain-rmse:0.131247\teval-rmspe:0.737256\ttrain-rmspe:0.167088\n",
      "[125]\teval-rmse:0.418089\ttrain-rmse:0.131031\teval-rmspe:0.737383\ttrain-rmspe:0.166688\n",
      "[126]\teval-rmse:0.419066\ttrain-rmse:0.130946\teval-rmspe:0.733563\ttrain-rmspe:0.166607\n",
      "[127]\teval-rmse:0.419082\ttrain-rmse:0.130759\teval-rmspe:0.733337\ttrain-rmspe:0.166454\n",
      "[128]\teval-rmse:0.418833\ttrain-rmse:0.130654\teval-rmspe:0.732031\ttrain-rmspe:0.1663\n",
      "[129]\teval-rmse:0.418833\ttrain-rmse:0.130396\teval-rmspe:0.732023\ttrain-rmspe:0.166079\n",
      "[130]\teval-rmse:0.418813\ttrain-rmse:0.130335\teval-rmspe:0.731954\ttrain-rmspe:0.165961\n",
      "[131]\teval-rmse:0.418887\ttrain-rmse:0.130093\teval-rmspe:0.732165\ttrain-rmspe:0.165802\n",
      "[132]\teval-rmse:0.41889\ttrain-rmse:0.129916\teval-rmspe:0.732228\ttrain-rmspe:0.165669\n",
      "[133]\teval-rmse:0.418603\ttrain-rmse:0.129834\teval-rmspe:0.731712\ttrain-rmspe:0.165625\n",
      "[134]\teval-rmse:0.418334\ttrain-rmse:0.129578\teval-rmspe:0.731342\ttrain-rmspe:0.164959\n",
      "[135]\teval-rmse:0.418278\ttrain-rmse:0.129261\teval-rmspe:0.731278\ttrain-rmspe:0.164862\n",
      "[136]\teval-rmse:0.41837\ttrain-rmse:0.129094\teval-rmspe:0.731293\ttrain-rmspe:0.164708\n",
      "[137]\teval-rmse:0.41847\ttrain-rmse:0.128977\teval-rmspe:0.731307\ttrain-rmspe:0.164611\n",
      "[138]\teval-rmse:0.41828\ttrain-rmse:0.128691\teval-rmspe:0.730816\ttrain-rmspe:0.164469\n",
      "[139]\teval-rmse:0.418724\ttrain-rmse:0.128415\teval-rmspe:0.731986\ttrain-rmspe:0.164259\n",
      "[140]\teval-rmse:0.418819\ttrain-rmse:0.128109\teval-rmspe:0.732331\ttrain-rmspe:0.163893\n",
      "[141]\teval-rmse:0.419031\ttrain-rmse:0.127906\teval-rmspe:0.732429\ttrain-rmspe:0.163775\n",
      "[142]\teval-rmse:0.419195\ttrain-rmse:0.127733\teval-rmspe:0.73254\ttrain-rmspe:0.163606\n",
      "[143]\teval-rmse:0.419215\ttrain-rmse:0.127572\teval-rmspe:0.733469\ttrain-rmspe:0.163593\n",
      "[144]\teval-rmse:0.419228\ttrain-rmse:0.127388\teval-rmspe:0.733436\ttrain-rmspe:0.163402\n",
      "[145]\teval-rmse:0.41921\ttrain-rmse:0.127158\teval-rmspe:0.734603\ttrain-rmspe:0.163163\n",
      "[146]\teval-rmse:0.419584\ttrain-rmse:0.127001\teval-rmspe:0.734893\ttrain-rmspe:0.163002\n",
      "[147]\teval-rmse:0.419699\ttrain-rmse:0.126856\teval-rmspe:0.735215\ttrain-rmspe:0.162864\n",
      "[148]\teval-rmse:0.419657\ttrain-rmse:0.126701\teval-rmspe:0.734333\ttrain-rmspe:0.162717\n",
      "[149]\teval-rmse:0.41964\ttrain-rmse:0.126458\teval-rmspe:0.734761\ttrain-rmspe:0.162389\n",
      "[150]\teval-rmse:0.419697\ttrain-rmse:0.126276\teval-rmspe:0.734933\ttrain-rmspe:0.162313\n",
      "[151]\teval-rmse:0.419861\ttrain-rmse:0.12606\teval-rmspe:0.732252\ttrain-rmspe:0.162118\n",
      "[152]\teval-rmse:0.419778\ttrain-rmse:0.12597\teval-rmspe:0.732191\ttrain-rmspe:0.162075\n",
      "[153]\teval-rmse:0.41976\ttrain-rmse:0.125786\teval-rmspe:0.732228\ttrain-rmspe:0.161987\n",
      "[154]\teval-rmse:0.419625\ttrain-rmse:0.125536\teval-rmspe:0.731506\ttrain-rmspe:0.161699\n",
      "[155]\teval-rmse:0.41963\ttrain-rmse:0.125297\teval-rmspe:0.73152\ttrain-rmspe:0.161606\n",
      "[156]\teval-rmse:0.419537\ttrain-rmse:0.125166\teval-rmspe:0.731819\ttrain-rmspe:0.16388\n",
      "[157]\teval-rmse:0.420165\ttrain-rmse:0.125008\teval-rmspe:0.732228\ttrain-rmspe:0.163791\n",
      "[158]\teval-rmse:0.420089\ttrain-rmse:0.124907\teval-rmspe:0.731711\ttrain-rmspe:0.163723\n",
      "[159]\teval-rmse:0.419905\ttrain-rmse:0.124817\teval-rmspe:0.731218\ttrain-rmspe:0.163638\n",
      "[160]\teval-rmse:0.41991\ttrain-rmse:0.124638\teval-rmspe:0.731327\ttrain-rmspe:0.163372\n",
      "[161]\teval-rmse:0.42002\ttrain-rmse:0.124457\teval-rmspe:0.733931\ttrain-rmspe:0.163196\n",
      "[162]\teval-rmse:0.420177\ttrain-rmse:0.124235\teval-rmspe:0.734726\ttrain-rmspe:0.163009\n",
      "[163]\teval-rmse:0.420117\ttrain-rmse:0.124131\teval-rmspe:0.734768\ttrain-rmspe:0.162937\n",
      "[164]\teval-rmse:0.420019\ttrain-rmse:0.123949\teval-rmspe:0.734637\ttrain-rmspe:0.162822\n",
      "[165]\teval-rmse:0.420051\ttrain-rmse:0.123794\teval-rmspe:0.734172\ttrain-rmspe:0.162703\n",
      "[166]\teval-rmse:0.420034\ttrain-rmse:0.123574\teval-rmspe:0.734749\ttrain-rmspe:0.162104\n",
      "[167]\teval-rmse:0.420009\ttrain-rmse:0.123402\teval-rmspe:0.734643\ttrain-rmspe:0.161967\n",
      "[168]\teval-rmse:0.419902\ttrain-rmse:0.123155\teval-rmspe:0.734307\ttrain-rmspe:0.161758\n",
      "[169]\teval-rmse:0.420007\ttrain-rmse:0.123033\teval-rmspe:0.734323\ttrain-rmspe:0.161672\n",
      "[170]\teval-rmse:0.420317\ttrain-rmse:0.122861\teval-rmspe:0.734453\ttrain-rmspe:0.153902\n",
      "[171]\teval-rmse:0.420358\ttrain-rmse:0.122741\teval-rmspe:0.734521\ttrain-rmspe:0.153771\n",
      "[172]\teval-rmse:0.42079\ttrain-rmse:0.122571\teval-rmspe:0.735256\ttrain-rmspe:0.153395\n",
      "[173]\teval-rmse:0.420785\ttrain-rmse:0.122491\teval-rmspe:0.735344\ttrain-rmspe:0.153332\n",
      "[174]\teval-rmse:0.422274\ttrain-rmse:0.122403\teval-rmspe:0.739264\ttrain-rmspe:0.153247\n",
      "[175]\teval-rmse:0.422325\ttrain-rmse:0.12223\teval-rmspe:0.739373\ttrain-rmspe:0.152817\n",
      "[176]\teval-rmse:0.422271\ttrain-rmse:0.122146\teval-rmspe:0.736917\ttrain-rmspe:0.152722\n",
      "[177]\teval-rmse:0.422108\ttrain-rmse:0.121984\teval-rmspe:0.736754\ttrain-rmspe:0.152312\n",
      "[178]\teval-rmse:0.422031\ttrain-rmse:0.121799\teval-rmspe:0.736642\ttrain-rmspe:0.151893\n",
      "[179]\teval-rmse:0.421901\ttrain-rmse:0.121663\teval-rmspe:0.736557\ttrain-rmspe:0.151774\n",
      "[180]\teval-rmse:0.421934\ttrain-rmse:0.121444\teval-rmspe:0.736718\ttrain-rmspe:0.15147\n",
      "[181]\teval-rmse:0.421831\ttrain-rmse:0.121337\teval-rmspe:0.736794\ttrain-rmspe:0.151368\n",
      "[182]\teval-rmse:0.421925\ttrain-rmse:0.121138\teval-rmspe:0.736712\ttrain-rmspe:0.151315\n",
      "[183]\teval-rmse:0.42189\ttrain-rmse:0.120955\teval-rmspe:0.736695\ttrain-rmspe:0.151206\n",
      "[184]\teval-rmse:0.422109\ttrain-rmse:0.120841\teval-rmspe:0.736919\ttrain-rmspe:0.151084\n",
      "[185]\teval-rmse:0.422064\ttrain-rmse:0.120718\teval-rmspe:0.737115\ttrain-rmspe:0.150926\n",
      "[186]\teval-rmse:0.422061\ttrain-rmse:0.120598\teval-rmspe:0.737239\ttrain-rmspe:0.150836\n",
      "[187]\teval-rmse:0.421988\ttrain-rmse:0.120417\teval-rmspe:0.737399\ttrain-rmspe:0.150712\n",
      "[188]\teval-rmse:0.421916\ttrain-rmse:0.120264\teval-rmspe:0.737373\ttrain-rmspe:0.150644\n",
      "[189]\teval-rmse:0.421949\ttrain-rmse:0.120096\teval-rmspe:0.73732\ttrain-rmspe:0.15054\n",
      "[190]\teval-rmse:0.421992\ttrain-rmse:0.119947\teval-rmspe:0.737228\ttrain-rmspe:0.150382\n",
      "[191]\teval-rmse:0.421862\ttrain-rmse:0.119827\teval-rmspe:0.736733\ttrain-rmspe:0.150306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192]\teval-rmse:0.421688\ttrain-rmse:0.119722\teval-rmspe:0.735834\ttrain-rmspe:0.150235\n",
      "[193]\teval-rmse:0.421612\ttrain-rmse:0.119664\teval-rmspe:0.73473\ttrain-rmspe:0.150187\n",
      "[194]\teval-rmse:0.42158\ttrain-rmse:0.1196\teval-rmspe:0.734475\ttrain-rmspe:0.150158\n",
      "[195]\teval-rmse:0.421804\ttrain-rmse:0.119356\teval-rmspe:0.734539\ttrain-rmspe:0.149866\n",
      "[196]\teval-rmse:0.421711\ttrain-rmse:0.119247\teval-rmspe:0.734313\ttrain-rmspe:0.149792\n",
      "[197]\teval-rmse:0.421821\ttrain-rmse:0.119193\teval-rmspe:0.73441\ttrain-rmspe:0.149739\n",
      "[198]\teval-rmse:0.42196\ttrain-rmse:0.119039\teval-rmspe:0.733919\ttrain-rmspe:0.14829\n",
      "[199]\teval-rmse:0.421886\ttrain-rmse:0.118943\teval-rmspe:0.734268\ttrain-rmspe:0.148218\n",
      "[200]\teval-rmse:0.421997\ttrain-rmse:0.118726\teval-rmspe:0.744022\ttrain-rmspe:0.148758\n",
      "[201]\teval-rmse:0.421934\ttrain-rmse:0.118543\teval-rmspe:0.744041\ttrain-rmspe:0.148536\n",
      "[202]\teval-rmse:0.421931\ttrain-rmse:0.118422\teval-rmspe:0.743951\ttrain-rmspe:0.148449\n",
      "[203]\teval-rmse:0.421911\ttrain-rmse:0.118376\teval-rmspe:0.74379\ttrain-rmspe:0.148423\n",
      "[204]\teval-rmse:0.422532\ttrain-rmse:0.118202\teval-rmspe:0.744052\ttrain-rmspe:0.148289\n",
      "[205]\teval-rmse:0.422532\ttrain-rmse:0.11807\teval-rmspe:0.743687\ttrain-rmspe:0.148208\n",
      "[206]\teval-rmse:0.422172\ttrain-rmse:0.117912\teval-rmspe:0.743012\ttrain-rmspe:0.148221\n",
      "[207]\teval-rmse:0.422199\ttrain-rmse:0.117842\teval-rmspe:0.743543\ttrain-rmspe:0.147254\n",
      "[208]\teval-rmse:0.422199\ttrain-rmse:0.117782\teval-rmspe:0.743525\ttrain-rmspe:0.147202\n",
      "[209]\teval-rmse:0.422315\ttrain-rmse:0.117599\teval-rmspe:0.743738\ttrain-rmspe:0.146779\n",
      "[210]\teval-rmse:0.422414\ttrain-rmse:0.117478\teval-rmspe:0.743986\ttrain-rmspe:0.146715\n",
      "[211]\teval-rmse:0.422452\ttrain-rmse:0.117447\teval-rmspe:0.744244\ttrain-rmspe:0.146687\n",
      "[212]\teval-rmse:0.422086\ttrain-rmse:0.117301\teval-rmspe:0.743012\ttrain-rmspe:0.146558\n",
      "[213]\teval-rmse:0.421955\ttrain-rmse:0.11723\teval-rmspe:0.743425\ttrain-rmspe:0.146483\n",
      "[214]\teval-rmse:0.421978\ttrain-rmse:0.117181\teval-rmspe:0.743634\ttrain-rmspe:0.146413\n",
      "[215]\teval-rmse:0.422061\ttrain-rmse:0.117028\teval-rmspe:0.743523\ttrain-rmspe:0.146597\n",
      "[216]\teval-rmse:0.422237\ttrain-rmse:0.116964\teval-rmspe:0.743656\ttrain-rmspe:0.146544\n",
      "[217]\teval-rmse:0.422809\ttrain-rmse:0.116875\teval-rmspe:0.747134\ttrain-rmspe:0.14647\n",
      "[218]\teval-rmse:0.422808\ttrain-rmse:0.116846\teval-rmspe:0.747132\ttrain-rmspe:0.146371\n",
      "[219]\teval-rmse:0.422734\ttrain-rmse:0.116627\teval-rmspe:0.74474\ttrain-rmspe:0.146201\n",
      "[220]\teval-rmse:0.422965\ttrain-rmse:0.116353\teval-rmspe:0.744872\ttrain-rmspe:0.146169\n",
      "[221]\teval-rmse:0.422989\ttrain-rmse:0.116279\teval-rmspe:0.743662\ttrain-rmspe:0.146104\n",
      "[222]\teval-rmse:0.422898\ttrain-rmse:0.116148\teval-rmspe:0.743635\ttrain-rmspe:0.146008\n",
      "[223]\teval-rmse:0.422814\ttrain-rmse:0.115971\teval-rmspe:0.743596\ttrain-rmspe:0.145885\n",
      "[224]\teval-rmse:0.422837\ttrain-rmse:0.115914\teval-rmspe:0.743661\ttrain-rmspe:0.145829\n",
      "[225]\teval-rmse:0.422773\ttrain-rmse:0.115804\teval-rmspe:0.743791\ttrain-rmspe:0.145721\n",
      "[226]\teval-rmse:0.422758\ttrain-rmse:0.115664\teval-rmspe:0.743259\ttrain-rmspe:0.14554\n",
      "[227]\teval-rmse:0.423291\ttrain-rmse:0.115518\teval-rmspe:0.744338\ttrain-rmspe:0.145397\n",
      "[228]\teval-rmse:0.423239\ttrain-rmse:0.115386\teval-rmspe:0.744144\ttrain-rmspe:0.145257\n",
      "[229]\teval-rmse:0.423208\ttrain-rmse:0.115337\teval-rmspe:0.743999\ttrain-rmspe:0.145183\n",
      "[230]\teval-rmse:0.423391\ttrain-rmse:0.115223\teval-rmspe:0.744027\ttrain-rmspe:0.145129\n",
      "[231]\teval-rmse:0.423407\ttrain-rmse:0.115138\teval-rmspe:0.743823\ttrain-rmspe:0.145042\n",
      "[232]\teval-rmse:0.423583\ttrain-rmse:0.115016\teval-rmspe:0.744065\ttrain-rmspe:0.144836\n",
      "[233]\teval-rmse:0.423758\ttrain-rmse:0.114942\teval-rmspe:0.744463\ttrain-rmspe:0.144784\n",
      "[234]\teval-rmse:0.423682\ttrain-rmse:0.114881\teval-rmspe:0.74429\ttrain-rmspe:0.14469\n",
      "[235]\teval-rmse:0.423492\ttrain-rmse:0.114826\teval-rmspe:0.743694\ttrain-rmspe:0.14456\n",
      "[236]\teval-rmse:0.423543\ttrain-rmse:0.114687\teval-rmspe:0.74562\ttrain-rmspe:0.144394\n",
      "[237]\teval-rmse:0.42355\ttrain-rmse:0.114618\teval-rmspe:0.745873\ttrain-rmspe:0.144326\n",
      "[238]\teval-rmse:0.423535\ttrain-rmse:0.114462\teval-rmspe:0.745635\ttrain-rmspe:0.144261\n",
      "[239]\teval-rmse:0.423605\ttrain-rmse:0.114387\teval-rmspe:0.7456\ttrain-rmspe:0.144225\n",
      "[240]\teval-rmse:0.423421\ttrain-rmse:0.114325\teval-rmspe:0.745278\ttrain-rmspe:0.144027\n",
      "[241]\teval-rmse:0.423505\ttrain-rmse:0.114235\teval-rmspe:0.744931\ttrain-rmspe:0.143997\n",
      "[242]\teval-rmse:0.423342\ttrain-rmse:0.114167\teval-rmspe:0.744288\ttrain-rmspe:0.143903\n",
      "[243]\teval-rmse:0.423467\ttrain-rmse:0.11412\teval-rmspe:0.744308\ttrain-rmspe:0.143868\n",
      "[244]\teval-rmse:0.423395\ttrain-rmse:0.113976\teval-rmspe:0.74408\ttrain-rmspe:0.143725\n",
      "[245]\teval-rmse:0.42332\ttrain-rmse:0.11388\teval-rmspe:0.744014\ttrain-rmspe:0.143647\n",
      "[246]\teval-rmse:0.423083\ttrain-rmse:0.113835\teval-rmspe:0.743654\ttrain-rmspe:0.143597\n",
      "[247]\teval-rmse:0.42308\ttrain-rmse:0.113646\teval-rmspe:0.742788\ttrain-rmspe:0.143588\n",
      "[248]\teval-rmse:0.423057\ttrain-rmse:0.11359\teval-rmspe:0.742425\ttrain-rmspe:0.14311\n",
      "[249]\teval-rmse:0.42309\ttrain-rmse:0.113538\teval-rmspe:0.742327\ttrain-rmspe:0.143142\n",
      "[250]\teval-rmse:0.423014\ttrain-rmse:0.113439\teval-rmspe:0.741906\ttrain-rmspe:0.143102\n",
      "[251]\teval-rmse:0.423059\ttrain-rmse:0.1133\teval-rmspe:0.741759\ttrain-rmspe:0.143025\n",
      "[252]\teval-rmse:0.423074\ttrain-rmse:0.113252\teval-rmspe:0.742155\ttrain-rmspe:0.142992\n",
      "[253]\teval-rmse:0.42308\ttrain-rmse:0.113212\teval-rmspe:0.742175\ttrain-rmspe:0.142916\n",
      "[254]\teval-rmse:0.423068\ttrain-rmse:0.113129\teval-rmspe:0.742169\ttrain-rmspe:0.142733\n",
      "[255]\teval-rmse:0.423046\ttrain-rmse:0.113047\teval-rmspe:0.741402\ttrain-rmspe:0.142724\n",
      "[256]\teval-rmse:0.423026\ttrain-rmse:0.113015\teval-rmspe:0.741371\ttrain-rmspe:0.142694\n",
      "[257]\teval-rmse:0.422972\ttrain-rmse:0.112945\teval-rmspe:0.741332\ttrain-rmspe:0.142608\n",
      "[258]\teval-rmse:0.423026\ttrain-rmse:0.112828\teval-rmspe:0.742435\ttrain-rmspe:0.141778\n",
      "[259]\teval-rmse:0.423085\ttrain-rmse:0.112762\teval-rmspe:0.742772\ttrain-rmspe:0.141722\n",
      "[260]\teval-rmse:0.42321\ttrain-rmse:0.112724\teval-rmspe:0.74326\ttrain-rmspe:0.141675\n",
      "[261]\teval-rmse:0.423214\ttrain-rmse:0.112666\teval-rmspe:0.743014\ttrain-rmspe:0.141536\n",
      "[262]\teval-rmse:0.422807\ttrain-rmse:0.112561\teval-rmspe:0.742219\ttrain-rmspe:0.141452\n",
      "[263]\teval-rmse:0.422841\ttrain-rmse:0.112489\teval-rmspe:0.742029\ttrain-rmspe:0.141399\n",
      "[264]\teval-rmse:0.422795\ttrain-rmse:0.112438\teval-rmspe:0.741465\ttrain-rmspe:0.141341\n",
      "[265]\teval-rmse:0.422818\ttrain-rmse:0.112367\teval-rmspe:0.741304\ttrain-rmspe:0.141295\n",
      "[266]\teval-rmse:0.422687\ttrain-rmse:0.11227\teval-rmspe:0.741375\ttrain-rmspe:0.141317\n",
      "[267]\teval-rmse:0.422549\ttrain-rmse:0.112241\teval-rmspe:0.740716\ttrain-rmspe:0.141233\n",
      "[268]\teval-rmse:0.423696\ttrain-rmse:0.112201\teval-rmspe:0.742762\ttrain-rmspe:0.141208\n",
      "[269]\teval-rmse:0.423628\ttrain-rmse:0.112069\teval-rmspe:0.74246\ttrain-rmspe:0.141057\n",
      "[270]\teval-rmse:0.423695\ttrain-rmse:0.111985\teval-rmspe:0.742449\ttrain-rmspe:0.141009\n",
      "[271]\teval-rmse:0.423854\ttrain-rmse:0.111908\teval-rmspe:0.742433\ttrain-rmspe:0.14095\n",
      "[272]\teval-rmse:0.42387\ttrain-rmse:0.111856\teval-rmspe:0.74236\ttrain-rmspe:0.140894\n",
      "[273]\teval-rmse:0.423492\ttrain-rmse:0.111758\teval-rmspe:0.742187\ttrain-rmspe:0.140817\n",
      "[274]\teval-rmse:0.423542\ttrain-rmse:0.111694\teval-rmspe:0.742473\ttrain-rmspe:0.140726\n",
      "[275]\teval-rmse:0.423747\ttrain-rmse:0.111637\teval-rmspe:0.742668\ttrain-rmspe:0.140692\n",
      "[276]\teval-rmse:0.423805\ttrain-rmse:0.111483\teval-rmspe:0.742841\ttrain-rmspe:0.141529\n",
      "[277]\teval-rmse:0.423597\ttrain-rmse:0.111413\teval-rmspe:0.741913\ttrain-rmspe:0.141484\n",
      "[278]\teval-rmse:0.423712\ttrain-rmse:0.111335\teval-rmspe:0.742251\ttrain-rmspe:0.141445\n",
      "[279]\teval-rmse:0.423632\ttrain-rmse:0.111264\teval-rmspe:0.742198\ttrain-rmspe:0.141397\n",
      "[280]\teval-rmse:0.42351\ttrain-rmse:0.111195\teval-rmspe:0.741954\ttrain-rmspe:0.141386\n",
      "[281]\teval-rmse:0.423728\ttrain-rmse:0.111132\teval-rmspe:0.741277\ttrain-rmspe:0.141325\n",
      "[282]\teval-rmse:0.423736\ttrain-rmse:0.111104\teval-rmspe:0.741315\ttrain-rmspe:0.141258\n",
      "[283]\teval-rmse:0.423871\ttrain-rmse:0.110994\teval-rmspe:0.74154\ttrain-rmspe:0.141201\n",
      "[284]\teval-rmse:0.424048\ttrain-rmse:0.11095\teval-rmspe:0.742476\ttrain-rmspe:0.141151\n",
      "[285]\teval-rmse:0.424067\ttrain-rmse:0.1109\teval-rmspe:0.742643\ttrain-rmspe:0.141097\n",
      "[286]\teval-rmse:0.424027\ttrain-rmse:0.110837\teval-rmspe:0.742223\ttrain-rmspe:0.141051\n",
      "[287]\teval-rmse:0.424133\ttrain-rmse:0.110748\teval-rmspe:0.742627\ttrain-rmspe:0.141035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[288]\teval-rmse:0.424062\ttrain-rmse:0.110594\teval-rmspe:0.741768\ttrain-rmspe:0.140941\n",
      "[289]\teval-rmse:0.424009\ttrain-rmse:0.110536\teval-rmspe:0.739429\ttrain-rmspe:0.140879\n",
      "[290]\teval-rmse:0.424006\ttrain-rmse:0.110489\teval-rmspe:0.739393\ttrain-rmspe:0.141541\n",
      "[291]\teval-rmse:0.424037\ttrain-rmse:0.110449\teval-rmspe:0.739931\ttrain-rmspe:0.141511\n",
      "[292]\teval-rmse:0.424197\ttrain-rmse:0.110408\teval-rmspe:0.740286\ttrain-rmspe:0.141453\n",
      "[293]\teval-rmse:0.424257\ttrain-rmse:0.110321\teval-rmspe:0.740323\ttrain-rmspe:0.141447\n",
      "[294]\teval-rmse:0.424141\ttrain-rmse:0.11026\teval-rmspe:0.740013\ttrain-rmspe:0.141407\n",
      "[295]\teval-rmse:0.424231\ttrain-rmse:0.110049\teval-rmspe:0.737973\ttrain-rmspe:0.14132\n",
      "[296]\teval-rmse:0.424259\ttrain-rmse:0.109904\teval-rmspe:0.738106\ttrain-rmspe:0.141244\n",
      "[297]\teval-rmse:0.424166\ttrain-rmse:0.109807\teval-rmspe:0.738134\ttrain-rmspe:0.139727\n",
      "[298]\teval-rmse:0.424203\ttrain-rmse:0.109678\teval-rmspe:0.738126\ttrain-rmspe:0.139425\n",
      "[299]\teval-rmse:0.424165\ttrain-rmse:0.109611\teval-rmspe:0.738299\ttrain-rmspe:0.139332\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, np.log(y_train.values + 1))\n",
    "dvalid = xgb.DMatrix(X_test, np.log(y_test.values + 1))\n",
    "dtest = xgb.DMatrix(test_pipline)\n",
    "\n",
    "watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "gbm = xgb.train(params, dtrain, num_trees, evals=watchlist, early_stopping_rounds=50, feval=rmspe_xg, verbose_eval=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = gbm.predict(xgb.DMatrix(test_pipline))\n",
    "\n",
    "submission = pd.DataFrame({\"Id\": df_test[\"Id\"], \"Sales\": np.exp(test_probs) - 1})\n",
    "submission.to_csv(\"xgboost_submission_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

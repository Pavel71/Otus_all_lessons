{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Реализовать и обучить сверточную нейронную сеть на Pytorch -- архитектура на ваш выбор. На датасете CIFAR10 (доступен в torchvision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"cnn\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)\n",
    "    \n",
    "    # функция для получения случайных индексов для обучения по батчам\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    \n",
    "    np.random.seed(epoch * n_batches + batch_index)  # not shown in the book\n",
    "    indices = np.random.randint(m, size=batch_size)  # not shown\n",
    "    X_batch = scaled_housing_data_plus_bias[indices] # not shown\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices] # not shown\n",
    "    return X_batch, y_batch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Достаем данные из кераса\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Итак кол-во классов #10\n",
    "n_classes = np.unique(y_train).shape[0]\n",
    "# _ это кол-во объектов,Длинна, ширина, канал # 32 32 3\n",
    "_,height,width,channels = X_train.shape\n",
    "# Кол-во признаков\n",
    "n_future = height * width * channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Смотрим на картинки! Все верно\n",
    "\n",
    "plt.imshow(X_train[2], cmap=\"gray\") # plot 1st image's 2nd feature map\n",
    "plt.title(y_train[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак пишем сверточную сеть с многоклассовой классификацией!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Итак кол-во классов #10\n",
    "n_classes = np.unique(y_train).shape[0]\n",
    "# _ это кол-во объектов,Длинна, ширина, канал # 32 32 3\n",
    "_,height,width,channels = X_train.shape\n",
    "# Кол-во признаков\n",
    "n_future = height * width * channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Scripts/Neural_Networks/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./Scripts/Neural_Networks/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./Scripts/Neural_Networks/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./Scripts/Neural_Networks/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./Scripts/Neural_Networks/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Архитектура сетки 2 сверточных слоя 32 и 64 фильтра\n",
    "# окно 3 на 3 \n",
    "# шаг окна 1(2)\n",
    "# дополняем 0 недостоющие пиксели\n",
    "# Дальше объяденяющий слой по максимуму\n",
    "# 1 полносвяззный слоя\n",
    "# и выходной слой с софтмак энтропией \n",
    "\n",
    "conv1_fmaps = 32\n",
    "conv1_ksize = 3\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "conv2_fmaps = 64\n",
    "conv2_ksize = 3\n",
    "conv2_stride = 2\n",
    "conv2_pad = \"SAME\"\n",
    "\n",
    "pool3_fmaps = conv2_fmaps\n",
    "\n",
    "n_fc1 = 64\n",
    "n_outputs = 10\n",
    "n_inputs = n_future\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "# 1. Определяем переменные заглушки для градиентного спуска\n",
    "X = tf.placeholder(dtype = tf.float32, shape=(None, 28*28*1), name=\"X\")\n",
    "X_reshape = tf.reshape(X , shape=(-1, 28, 28, 1))\n",
    "\n",
    "# X = tf.placeholder(dtype = tf.float32, shape = (None,height,width,channels), name = 'X')\n",
    "y = tf.placeholder(dtype = tf.int32, shape = (None), name = 'y')\n",
    "\n",
    "# 2. Прописываем архитектруру сетки\n",
    "with tf.name_scope('conv'):\n",
    "    \n",
    "    conv1d = tf.layers.conv2d(X_reshape, filters = 32, kernel_size = 3, strides = 1,padding=\"SAME\",\n",
    "                              activation = tf.nn.relu, name = 'conv1')\n",
    "    \n",
    "    conv2d = tf.layers.conv2d(conv1d,filters = 64,kernel_size = 3,strides = 2,padding='SAME',\n",
    "                              activation = tf.nn.relu, name = 'conv2')\n",
    "    \n",
    "with tf.name_scope('max_poll'):\n",
    "    \n",
    "#     pool = tf.layers.max_pooling2d(conv2d, pool_size=[2, 2], strides=2, padding='VALID')\n",
    "    \n",
    "    pool3 = tf.nn.max_pool(conv2d, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 7 * 7])\n",
    "    \n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool3_flat, n_fc1, activation=tf.nn.relu, name=\"fc1\") \n",
    "\n",
    "with tf.name_scope('output'):\n",
    "    # Нужно получить выходной слой чтобы потом применить на нем софтмакс активацию\n",
    "    \n",
    "    logits = tf.layers.dense(fc1,n_outputs,name = 'logits')\n",
    "    \n",
    "    # Получаю энтропию и высчитваем ошибку\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name='loss')\n",
    "    \n",
    "    # Подсчитаем также вероятность\n",
    "    \n",
    "#     softmax = tf.layers.dense(fc1, n_outputs, activation=tf.nn.softmax, name='logits')\n",
    "    \n",
    "    \n",
    "    y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "    \n",
    "#     y_pred_cls = tf.argmax(softmax, axis=1)\n",
    "    \n",
    "#     loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=softmax, labels=y))\n",
    "    \n",
    "#     loss = tf.losses.softmax_cross_entropy(y, y_pred_cls) \n",
    "    \n",
    "with tf.name_scope('train'): \n",
    "    \n",
    "    # Применим АдамОптимизатор\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=0.01,momentum=0.9,name='optimizer').minimize(loss)\n",
    "    \n",
    "with tf.name_scope('accuracy'):\n",
    "    \n",
    "#     correct_prediction = tf.equal(y_pred_cls, tf.argmax(y, axis=1))\n",
    "#     accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    # Подсчитаем точность\n",
    "    # Получим булевые ответы на вероятность угадать класс\n",
    "    correct = tf.nn.in_top_k(logits, y,1)\n",
    "    # Точность\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,dtype=tf.float32),name='accuracy')\n",
    "    \n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.97 Test accuracy: 0.9622\n",
      "1 Train accuracy: 0.98 Test accuracy: 0.9741\n",
      "2 Train accuracy: 0.97 Test accuracy: 0.9783\n",
      "3 Train accuracy: 0.98 Test accuracy: 0.9797\n",
      "4 Train accuracy: 0.98 Test accuracy: 0.9843\n",
      "5 Train accuracy: 0.97 Test accuracy: 0.9862\n",
      "6 Train accuracy: 1.0 Test accuracy: 0.9868\n",
      "7 Train accuracy: 0.99 Test accuracy: 0.9871\n",
      "8 Train accuracy: 0.99 Test accuracy: 0.9869\n",
      "9 Train accuracy: 1.0 Test accuracy: 0.9879\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            \n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            sess.run(optimizer, feed_dict={X: X_batch, y: y_batch})\n",
    "            \n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "        \n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "\n",
    "        save_path = saver.save(sess, \"./my_mnist_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Достаем данные из кераса\n",
    "from keras.datasets import cifar10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "X_train_255 = X_train.astype('float32')\n",
    "X_test_255 = X_test.astype('float32') \n",
    "X_train_255 /= 255\n",
    "X_test_255 /= 255\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Архитектура сетки 2 сверточных слоя 32 и 64 фильтра\n",
    "# окно 3 на 3 \n",
    "# шаг окна 1(2)\n",
    "# дополняем 0 недостоющие пиксели\n",
    "# Дальше объяденяющий слой по максимуму\n",
    "# 1 полносвяззный слоя\n",
    "# и выходной слой с софтмак энтропией \n",
    "\n",
    "conv1_fmaps = 32\n",
    "conv1_ksize = 3\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "conv2_fmaps = 64\n",
    "conv2_ksize = 3\n",
    "conv2_stride = 2\n",
    "conv2_pad = \"SAME\"\n",
    "\n",
    "pool3_fmaps = conv2_fmaps\n",
    "\n",
    "n_fc1 = 64\n",
    "n_outputs = 10\n",
    "n_inputs = n_future\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "# 1. Определяем переменные заглушки для градиентного спуска\n",
    "X = tf.placeholder(dtype = tf.float32, shape=(None, 32,32,3), name=\"X\")\n",
    "# X_reshape = tf.reshape(X , shape=(-1, 32, 32, 3))\n",
    "\n",
    "# X = tf.placeholder(dtype = tf.float32, shape = (None,height,width,channels), name = 'X')\n",
    "y = tf.placeholder(dtype = tf.int32, shape = (None), name = 'y')\n",
    "\n",
    "# Делаем переменную traning для батч нормализации\n",
    "training = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "# 2. Прописываем архитектруру сетки\n",
    "with tf.name_scope('conv1'):\n",
    "    \n",
    "    conv1d = tf.layers.conv2d(X, filters = 32, \n",
    "                              kernel_size = 3, \n",
    "                              strides = 1,\n",
    "                              padding=\"SAME\",\n",
    "                              activation = tf.nn.relu,\n",
    "                              kernel_initializer=he_init,\n",
    "                              name = 'conv1_1')\n",
    "    \n",
    "    conv1_2d = tf.layers.conv2d(conv1d,filters = 64,\n",
    "                                kernel_size = 3,\n",
    "                                strides = 1,\n",
    "                                padding='SAME',\n",
    "                                activation = tf.nn.relu,\n",
    "                                kernel_initializer=he_init,\n",
    "                                name = 'conv1_2')\n",
    "        \n",
    "    pool1 = tf.layers.max_pooling2d(conv1_2d, pool_size=[2, 2], strides=2, padding='VALID')\n",
    "    drop1 = tf.layers.dropout(pool1, rate=0.25, training=training, name='drop1')\n",
    "    \n",
    "with tf.variable_scope('conv2') as scope:\n",
    "    \n",
    "    conv2d = tf.layers.conv2d(\n",
    "            inputs=drop1,\n",
    "            filters=128,\n",
    "            kernel_size=[3, 3],\n",
    "            padding='SAME',\n",
    "            activation=tf.nn.relu,\n",
    "            kernel_initializer=he_init\n",
    "        )\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(conv2d, pool_size=[2, 2], strides=2, padding='SAME')\n",
    "    conv2_2d = tf.layers.conv2d(\n",
    "            inputs=pool2 ,\n",
    "            filters=128,\n",
    "            kernel_size=[2, 2],\n",
    "            padding='SAME',\n",
    "            activation=tf.nn.relu,\n",
    "            kernel_initializer=he_init    \n",
    "        )\n",
    "    \n",
    "    pool3 = tf.layers.max_pooling2d(conv2_2d, pool_size=[2, 2], strides=2, padding='SAME')\n",
    "    drop2 = tf.layers.dropout(pool3, rate=0.25, training=training, name='drop2')    \n",
    "    \n",
    "    \n",
    "    drop_flat = tf.reshape(drop2, shape=[-1, 128 * 4 * 4])\n",
    "    \n",
    "with tf.name_scope(\"fc1\"):\n",
    "    \n",
    "    fc1 = tf.layers.dense(drop_flat, 1500, \n",
    "                          activation=tf.nn.relu,\n",
    "                          kernel_initializer=he_init,\n",
    "                          name=\"fc1\")\n",
    "    \n",
    "\n",
    "with tf.name_scope('output'):\n",
    "    # Нужно получить выходной слой чтобы потом применить на нем софтмакс активацию\n",
    "    \n",
    "    logits = tf.layers.dense(fc1,n_outputs,name = 'logits')\n",
    "    \n",
    "    # Получаю энтропию и высчитваем ошибку\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name='loss')\n",
    "    \n",
    "    # для предикта\n",
    "    y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "    \n",
    "\n",
    "    \n",
    "with tf.name_scope('train'): \n",
    "    \n",
    "    # Применим АдамОптимизатор\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01,\n",
    "                                   beta1=0.9,\n",
    "                                   beta2=0.999,\n",
    "                                   epsilon=1e-08,\n",
    "                                   name='optimizer').minimize(loss)\n",
    "    \n",
    "with tf.name_scope('accuracy'):\n",
    "    \n",
    "#     correct_prediction = tf.equal(y_pred_cls, tf.argmax(y, axis=1))\n",
    "#     accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    # Подсчитаем точность\n",
    "    # Получим булевые ответы на вероятность угадать класс\n",
    "    correct = tf.nn.in_top_k(logits, y,1)\n",
    "    # Точность\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,dtype=tf.float32),name='accuracy')\n",
    "    \n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.48 Test accuracy: 0.3797\n",
      "1 Train accuracy: 0.41 Test accuracy: 0.431\n",
      "2 Train accuracy: 0.39 Test accuracy: 0.4134\n",
      "3 Train accuracy: 0.46 Test accuracy: 0.4626\n",
      "4 Train accuracy: 0.41 Test accuracy: 0.4535\n",
      "5 Train accuracy: 0.45 Test accuracy: 0.4511\n",
      "6 Train accuracy: 0.53 Test accuracy: 0.4852\n",
      "7 Train accuracy: 0.41 Test accuracy: 0.4736\n",
      "8 Train accuracy: 0.48 Test accuracy: 0.4666\n",
      "9 Train accuracy: 0.57 Test accuracy: 0.4845\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 10\n",
    "n_batchs = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for iteration in range(X_train.shape[0] // n_batchs):\n",
    "            \n",
    "            indices = np.random.randint(X_train.shape[0], size=n_batchs)\n",
    "            \n",
    "            X_batch, y_batch = X_train_255[indices],y_train[indices].flatten()\n",
    "            \n",
    "            sess.run(optimizer,feed_dict = {X:X_batch,y:y_batch,training: True})\n",
    "            \n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})            \n",
    "        accuracy_test = accuracy.eval(feed_dict = {X:X_test_255,y:y_test.flatten()}) \n",
    " \n",
    "        \n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", accuracy_test)\n",
    "\n",
    "        save_path = saver.save(sess, \"./my_cf10n_model2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вообщем при наличии времени и технической возможности можно обучить сетку 60 -100 эпох тогда скор будет выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
